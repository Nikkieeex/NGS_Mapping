---
title: "Logboek_samen"
output: html_document
---

## 29-9-2025

Vandaag gaan we bezig met week 3 van de les stof en de eerste opdracht hierin is dat we de BED-data gaan lezen.


*Opdracht 1:*

```{r}
BED_file <-read.table("/commons/Themas/Thema05/2025/CardioPanel/CAR_0394321__en-20_target_v2_hg38.bed")
head(BED_file)
```

Omdat de columns geen namen hebben word dit autotmatisch v1 v2, dit moeten we veranderen:

```{r}
names(BED_file)<- c("chromosome", "begin", "end","gene")
head(BED_file)
```

## 30-9-2025 
Vandaag ga ik verder met wat ik gisteren gestart was, ik volg gewoon de stappen van week 3 nog.

Het printen van de exons nummers per chromosoom, in elke rij zit 1 exon dus ik moet eigenlijk gewoon de hele tabel printen?

```{r}
exons <- table(BED_file$chromosome)
exons
```

Hier is te zien hoeveel exonen er per chromosoom zijn deze kan je plotten:

```{r}
barplot(exons,
        ylab = "Exonen nummers",
        las = 2)
```

*opdracht 2:*

Het visualiseren van de nummers van genen per chromosoom, hiervoor moeten we een subset creeeren met elke unieke chromosoom-genen combinatie. Hiervoor kunnen we de table functie weer gebruiken.
```{r}
# selecteren van de chromosoom en gene columns
chrom_gene <- BED_file[, c("chromosome", "gene")]

# het verwijderen van duplicates 
unique_genes <- unique(chrom_gene)

# tellen van genen per chromosoom
gene_counts <- table(unique_genes$chromosome)

# Plotten van het resultaat
barplot(gene_counts,
        ylab = "Aantal unieke genen per chromosoom",
        las = 2)  # Draait de x-as labels verticaal voor betere leesbaarheid
```

_opdracht 3:_

libraries wat we gaan gebruiken:
```{r}
## Only needed when the package is missing
if (!require("BiocManager"))
    install.packages("BiocManager")

BiocManager::install("GenomicRanges")
```
```{r}
# This package contains the 'IRanges', 'GRanges' and 'GRangesList' classes we will use
library(GenomicRanges)
```

```{r}
# print alle rijen waar alle genomen SOD2 zijn
sod2 <- BED_file[BED_file$gene == "SOD2", ]
```

```{r}
# wijs de hele kolom toe aan IRanges argumenten
ranges <- IRanges(start = sod2$begin,
                  end = sod2$end,
                  names = sod2$gene)
ranges
```
IRanges word gebruikt om een soort van lijst te maken zodat R precies weet waar elk stukje begint, eindigt en hoe die heet. Dit is makkelijk om makkelijk te zien of er stukjes overlappen, of om te zoeken naar bepaalde regios. 

```{r}
# het berekenen van de lengte van een gene
cat("Lengte van SOD2:", sum( width( ranges) ), "bp")
```

Hier zie je eigenlijk hetzelfde als dat met de IRanges maar er missen enkele gegevens, daarom gaan we het IRanges omzetten naar GRanges, dit doen we om eigenlijk extra biologische data toe te voegen.
```{r}
granges <- GRanges(seqnames = sod2$chromosome,
                   ranges = ranges)
granges
```
Wat kunnen we nu eigenlijk met de granges? Met alleen de BED-data niet zo heel veel, maar we gaan de Pileup data ook in een vergelijkbare GRanges object plaatsen, hiermee kunnen we met onze data interessante vragen stellen met de pileup functie. Bijvoorbeeld specifiek iets vragen over exonen en de rest negeren. 

Voor dat we dat kunnen doen moeten we eerst de BED-data in het goede formaat zetten. 

De eerste stap hierbij een lege lijst creeeren:
```{r}
my_list <- list()
```

De tweede stap is om te itereren over alle genen in het BED-bestand:
```{r}
# split het BED-bestand op gene
gene_group <- split(BED_file, BED_file$gene)

# Itereer over elke gene
for (gene_name in names(gene_group)) {
  gene_data <- gene_group[[gene_name]]
  # Maak een GRanges object
  gr <- GRanges(seqnames = gene_data$chromosome,
                ranges = IRanges(start = gene_data$begin, end = gene_data$end),
                gene = gene_name)
  
  # Voeg toe aan de lijst
  my_list[[gene_name]] <- gr
}

# Zet de lijst om naar een GRangesList
my_list <- GRangesList(my_list)

my_list
```
```{r}
my_list["SOD2"]
```

dit werkt dus mooi:D.

_opdracht 4_
In deze opdracht moeten we nog een visualisatie maken gebaseerd op de BED-data maar nu gebruiken we de GRange object.

```{r}
psen2_ranges <- ranges(BED_file[['PSEN2']])
paste("Length of the 'PSEN2' gene:", sum(width(psen2_ranges)), "\n")
```
Hier kom ik ff niet verder en ga hier morgen denk ik verder aan werken.

## 01-10-2025


Vandaag ga ik verder met **opdracht 4 t/m 7**


_opdracht 4_ 

Genlengten (exonen) en visualisatie

Per gen de totale lengte in bp (som van exonlengten) berekenen en een overzichtsplot maken

```{r}
# Lengte van een specifiek gen (voorbeeld PSEN2) en som van exonbreedtes
psen2_ranges <- ranges(my_list[["PSEN2"]])
paste("Lengte van 'PSEN2' (exonen):", sum(width(psen2_ranges)), "bp")

# Alle genlengten (som van exonen per gen)
gene_lengths <- sapply(my_list, function(gr) sum(width(gr)))
gene_lengths <- sort(gene_lengths, decreasing = TRUE)

# Basale barplot, lange genen kunnen de schaal domineren
barplot(gene_lengths,
        las = 2,
        ylab = "Genlengte (som exonen, bp)",
        main = "Exon-gebaseerde genlengten (panel)")
```

Je ziet dat sommige genen veel langer zijn, waardoor de rest moeilijk te vergelijken is. Als TTN er niet tussen stond kon je beter verschillen zien. 


_opdracht 5_ 

BAM-bestand laden en pileup voor één gen en Rsamtools gebruiken
En bam en bai files nog op logische plek zetten

```{r}
if (!requireNamespace("Rsamtools", quietly = TRUE)) BiocManager::install("Rsamtools")
library(Rsamtools)

# JOHANNA PAS DIT PAD NOG AAN
bam_path <- "C:/Users/nicol/Documents/NGS_en_Genetics/MarkDuplicates on collection 28_BAM/bestand.bam"
bai_path <- "C:/Users/nicol/Documents/NGS_en_Genetics/MarkDuplicates on collection 28_BAM/bestand.bam.bai"

# Controle
bam_file <- BamFile(bam_path, index = bai_path)

# Test op 1 gen voorbeeld SOD2
test_gene <- "SOD2"
test_ranges <- my_list[[test_gene]]

# Pileup zonder onderscheid naar strand naar totale dekking per base
pu_params <- PileupParam(distinguish_nucleotides = FALSE,
                         distinguish_strands    = FALSE)

test_pileup <- pileup(file = bam_file,
                      scanBamParam = ScanBamParam(which = test_ranges),
                      pileupParam  = pu_params)

head(test_pileup)
```
beschrijf dit nog evne


_opdracht 6_

Pileup verwerken voor alle genen en in een lijst opslaan voor latere aggregatie

```{r}
coverage_list <- list()

for (g in names(my_list)) {
  gr <- my_list[[g]]
  pu <- pileup(file = bam_file,
               scanBamParam = ScanBamParam(which = gr),
               pileupParam  = pu_params)
  if (nrow(pu) > 0) {
    pu$gene <- g
  } else {
    # lege df met juiste kolommen
    pu <- data.frame(seqnames = character(),
                     pos      = integer(),
                     count    = integer(),
                     gene     = character())
  }
  coverage_list[[g]] <- pu
}

# Snelle sanity-check op een gen dat zeker in de panel zit
head(coverage_list[[test_gene]])
```

coverage_list bevat nu per gen een data.frame met minimaal kolommen pos, count, gene. Lege data.frames duiden op 0 reads in de targetregio.


_opdracht 7_

Coverage berekenen en rapporteren

per gen rapporteren:
aantal basen
gemiddelde dekking
aantal posities met lange dekking en percentage


```{r}
options(stringsAsFactors = FALSE)

gene_metrics <- data.frame(
  gene            = names(my_list),
  length_bp       = as.integer(sapply(my_list, function(gr) sum(width(gr)))),
  total_coverage  = numeric(length(my_list)),
  avg_coverage    = numeric(length(my_list)),
  low_cover_bases = integer(length(my_list)),
  low_cover_pct   = numeric(length(my_list))
)

for (g in names(my_list)) {
  gene_len <- sum(width(my_list[[g]]))
  df <- coverage_list[[g]]

  if (nrow(df) > 0) {
    # df$count is totale dekking per base (strand/nucleotide al samengenomen)
    total_cov <- sum(df$count)
    high_cov_positions <- sum(df$count >= 30)
  } else {
    total_cov <- 0
    high_cov_positions <- 0
  }

  low_cov_positions <- gene_len - high_cov_positions
  avg_cov <- if (gene_len > 0) total_cov / gene_len else 0

  gene_metrics[gene_metrics$gene == g, "total_coverage"]  <- total_cov
  gene_metrics[gene_metrics$gene == g, "avg_coverage"]    <- avg_cov
  gene_metrics[gene_metrics$gene == g, "low_cover_bases"] <- low_cov_positions
  gene_metrics[gene_metrics$gene == g, "low_cover_pct"]   <- (low_cov_positions / gene_len) * 100
}

# Sorteren op % lage dekking aflopend
gene_metrics <- gene_metrics[order(-gene_metrics$low_cover_pct, gene_metrics$gene), ]

```


##3-10-2025

Mijn doel voor vandaag is om met week 4 te starten, nicole en ik zijn allebei ermee bezig omdat het bij nicole niet helemaal goed gaat met downloaden. 

Met de BAM file en waar mark duplicates op is toegepast, ga ik de call variants tool van LoFreq gebruiken, met het GRCh38 referentie genoom. Ik laat de Call variants across setting aan met het gehele genoom referentie. 

Het resultaat van deze tool zou uiteindelijk een nieuwe file worden (vcf), elke lijn beschrijft een single variant. In galaxy kan je makkelijk zien hoeveel varianten er zijn. Noteer de 17 comment lines aan het begin van de file.
_Opdracht 8:_
Omdat we met patienten data werken gaan we ook volgends de richtlijnen werken van UMCG. Dit houdt in dat sequenties met een minimale waarde van 30% behouden word. Alles wat hier niet aan voldoet word eruit gefiltered.

Voor het filteren zijn er 1306 varianten. 

Inlezen van de data frame met read.delim functie, moeten we zeker zijn dat het bestand een goede header heeft met 18 comments, dit klopt. Ook moeten we de stringsAsFactors = FALSE argument toepassen, anders werkt het simpelweg niet omdat we geen R factor kunnen splitten. 
```{r}

# lees data vanaf lijn 18
variant_data <- read.delim("../data/voor_filtering.vcf",
                           header = TRUE,
                           skip = 17, # zorgt dat line 18 header is
                           stringsAsFactors = FALSE )

str(variant_data)
head(variant_data)
```

splitten van de kolom met strsplit functie, de output van deze functie is een lijst waar elk item een vector is, met gescheiden items. We gaan blijkbaar R magie gebruiken om dit te veranderen in een matrix:D.
```{r}
bed_splitted <- strsplit(variant_data$INFO,";")

bed_matrix <- do.call(rbind, bed_splitted)
head(bed_matrix, n = 20)

```
De eerste stap om nu te nemen is om het AF te verwijderen van de 2e rij. Daarna wil je het numeric maken, na het numeric maken wil je als een gescheiden variabel bewaren. 
```{r}
AF_clean <- gsub("^AF=", "", bed_matrix[, 2]) # verwijderd AF van de rij
AF_numeric <- as.numeric(AF_clean) # maakt de kolom numeric
no_AF <- AF_numeric # sla op als eigen variabel
```

De volgende stap is weer een GRanges maken waarbij de start en eind parameters een pos kolom krijgen. 
```{r}
nrow(bed_matrix)         # moet 1306 zijn
length(variant_data$X.CHROM)       # moet 1306 zijn
length(variant_data$POS) # moet 1306 zijn
```

```{r}
gr2 <- GRanges(
  seqnames = variant_data$X.CHROM,
  ranges = IRanges(start = variant_data$POS, end = variant_data$POS),
  strand = "*"
)

mcols(gr2) <- DataFrame(frequency = AF_numeric)

print(gr2)
```
De volgende stap is om alle varianten te krijgen van een exon. Dit moet met de findOverlap functie:
https://www.rdocumentation.org/packages/GenomicAlignments/versions/1.8.4/topics/findOverlaps-methods

```{r}
exons_gr <- GRanges(
  seqnames = BED_file$chromosome,
  ranges = IRanges(start = BED_file$begin, end = BED_file$end),
  strand = "*",
  gene = BED_file$gene
)
```


```{r}
# hits is een object (container) 
hits <- findOverlaps( query = gr2, subject = exons_gr)
hits_df <- DataFrame(hits)

```

```{r}
hits
hits_df
```
Je zou twee kolommen moeten krijgen waarvan 1 queryHits en de andere subjectHits, dit klopt. De volgende stap is het filteren op die 30%, dit kunnen we doen met het creeeren van nog een subset. 

```{r}
# de hits wie we willen houden omdat ze binnen het exon vallen


# freq voor frequency
freqs <- gr2$frequency

# filter voor 30%
freq_filter <- which(freqs >= 0.30)

# combineren van de filters
final_rows <- intersect(hits_df$queryHits, freq_filter)
variants_in_exons <- gr2[final_rows]
final_rows
```
Het vcf bestand overschrijven:
```{r}
vcf_lines <- readLines("../data/voor_filtering.vcf")

header <- vcf_lines[1:18]
body <- vcf_lines[18:length(vcf_lines)]

vcf_filtered <- c(header, body[final_rows+18])

#writeLines(vcf_filtered, "../data/na_filtering.vcf")
```

Dit is als het goed is opgeslagen nu dus de volgende stap is dit bestand uploaden in galaxy. 

_opdracht 9_
Voor deze opdracht 2 simpele visualizaties:

de visualisatie van de allelen frequency for alle overgebleven varianten:
```{r}
hist(variants_in_exons$frequency, breaks = 20,
     col = "skyblue", main = "Allele Frequency spreiding",
     xlab = "Allele Frequency", ylab = "Aantal varianten")
```
Ik zie vooral pieken bij rond de 50/60% dit betekent dat het heterozygote varianten. 

De tweede visualisatie is varianten per gen visualiseren:
```{r}
variant_counts <- table(hits_df$subjectHits)

variant_df <- as.data.frame(variant_counts)
colnames(variant_df) <- c("gene_index", "variant_count")

variant_df$gene <- names(exons_grl)[as.integer(variant_df$gene_index)]

barplot(variant_df$variant_count,
        names.arg = variant_df$gene,
        las = 2,
        col = "pink",
        main = "Aantal varianten per gen",
        xlab = "Gen",
        ylab = "Aantal varianten",
        cex.names = 0.7)
```

De volgende stap is in galaxy het bestand wat we net gefiltreerd hebben (vcf), te vergelijken met een aantal data bases. Deze data bases bevatten annotatiesgegevens voor bekende varianten. 

Met SnpEff gaan wij de varianten annoteren, met behulp van de GRCh38.105- database. Ook word er extra informatie toegevoegd met betrekking van het gen, dit geeft dus extra resultaten en dit word gedocumonteerd in het na_filtering.vcf.

Stap 2 is SnpSift, daarvoor ben je de dnSnp database nodig die gebruik ik als in de opdracht bij week 4. 

## 6-10-2025

Vandaag ga ik verder met de opdrachten. 
 
Ik was gebleven bij de dnSnp stap, dit was simpelweg uploaden en het enigste wat ik veranderd heb kwa settings. Only annotate ID field (do not add INFO field) deze stap op NO selecteren. 

Voor stap 3 gaan we annotaten met de dnSnp tool en de SnpSift, de stappen worden zoals bij de opdracht gevolgd.

##10-10-2025
Vandaag ga ik verder met de bovenstaande stap annotie met SNpEff

```{bash}
java -jar /data/datasets/dbNSFP/snpEff/SnpSift.jar DbNsfp -db /data/datasets/dbNSFP/snpEff/data/dbNSFP4.3c.txt.gz ~/Desktop/variant_step2.vcf > ~/Desktop/variants_step3.vcf
```

| Field ID                  | Source Database     | Value Type / Description                                      |
|---------------------------|---------------------|---------------------------------------------------------------|
| DP                        | LoFreq              | Integer: Raw read depth                                       |
| AF                        | LoFreq              | Float: Allele frequency                                       |
| SB                        | LoFreq              | Integer: Strand bias (Phred-scaled)                           |
| DP4                       | LoFreq              | Integer[4]: Ref/alt forward/reverse base counts               |
| INDEL                     | LoFreq              | Flag: Indicates INDEL variant                                 |
| CONSVAR                   | LoFreq              | Flag: Consensus variant indicator                             |
| HRUN                      | LoFreq              | Integer: Homopolymer run length                               |
| ANN                       | SnpEff              | String: Functional annotation (gene, impact, consequence, etc.) |
| LOF                       | SnpEff              | String: Predicted loss-of-function annotation                 |
| NMD                       | SnpEff              | String: Nonsense-mediated decay prediction                    |
| DBVARID                   | dbVar               | String: Structural variant accession ID                       |
| MC                        | dbSNP / ClinVar     | String: Molecular consequence (SO terms)                      |
| CLNDN                     | ClinVar             | String: Disease name                                          |
| ALLELEID                  | ClinVar             | Integer: Allele ID                                            |
| CLNVC                     | ClinVar             | String: Variant type                                          |
| CLNSIG                    | ClinVar             | String: Clinical significance                                 |
| CLNVCSO                   | ClinVar             | String: Sequence Ontology ID                                  |
| CLNVI                     | ClinVar             | String: Source database and variant ID                        |
| CLNREVSTAT               | ClinVar             | String: Review status                                         |
| CLNSIGINCL                | ClinVar             | String: Clinical significance for haplotype/genotype          |
| RS                        | dbSNP               | String: rsID (SNP identifier)                                 |
| CLNDISDB                  | ClinVar             | String: Disease database and identifier                       |
| GENEINFO                  | ClinVar             | String: Gene symbol and ID                                    |
| AF_EXAC / AF_ESP / AF_TGP | ExAC / ESP / TGP    | Float: Population allele frequencies                          |
| ORIGIN                    | ClinVar             | String: Allele origin codes                                   |
| CLNSIGCONF                | ClinVar             | String: Conflicting clinical significance                     |
| CLNHGVS                   | ClinVar             | String: HGVS expression                                       |
| dbNSFP_*                  | dbNSFP              | Various: Predictive scores, allele counts, conservation, etc. |


De volgende stap is om de SnpEff tool te runnen met CHROM POS REF ALT ANN[*].EFFECT ANN[*].IMPACT ANN[*].GENE ANN[*].FEATURE ANN[*].FEATUREID ANN[*].BIOTYPE ANN[*].ERRORS CLNDN CLNSIG deze fields to extract. (extract_tool.tabular)

Daarna de tool runnen met CHROM,POS,REF,ALT,dbNSFP_SIFT_pred,dbNSFP_SIFT_score,dbNSFP_Polyphen2_HDIV_pred,dbNSFP_Polyphen2_HDIV_score,dbNSFP_MutationAssessor_pred,dbNSFP_MutationAssessor_score,dbNSFP_MetaSVM_pred,dbNSFP_MetaSVM_score,dbNSFP_CADD_phred,dbNSFP_REVEL_score,dbNSFP_GERP___RS,dbNSFP_phastCons100way_vertebrate (extract_tool2.tabular)

De volgende stap is het vinden van de varianten dat doe ik als volg en ga stap bi jstap aan langs. 

natuurlijk eerst de data laden
```{r}
ann <- read.delim("data/extract_tool.tabular", header = TRUE, sep = "\t")
dbnsfp <- read.delim("data/extract_tool2.tabular", header = TRUE, sep = "\t")

```

kijken naar de kolom namen
```{r}
colnames(ann)
colnames(dbnsfp)
```

Clean up van de kolom namen
```{r}
names(ann) <- gsub("\\.+", ".", names(ann))
names(dbnsfp) <- gsub("\\.+", ".", names(dbnsfp))
```

weer kijken naar de kolom namen
```{r}
colnames(ann)
colnames(dbnsfp)
```


dat ziet er beter uit. Nu kan ik de data mergen met elkaar. 
```{r}
merged <- merge(ann, dbnsfp, by = c("CHROM", "POS", "REF", "ALT"))
```

```{r}

```
huh


